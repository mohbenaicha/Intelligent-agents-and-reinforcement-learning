{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "295d804e",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "This implementation incorporates three new elements:\n",
    "1. A beeline which the agents keeps track of in order to find the shortest way back after finding the gold\n",
    "2. the shortest number of turns required to start returning after finding the gold\n",
    "3. the shortest way back that involves the least number of turns resulting in the best score\n",
    "\n",
    "Simulation is at the end. A loop is a also setup to test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98030d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from collections import namedtuple\n",
    "from IPython.display import display\n",
    "from enum import Enum\n",
    "from pomegranate import *\n",
    "from pit_wumpus_networks import *\n",
    "from env_perc_act_kb import *\n",
    "\n",
    "Agent, Pit, Wumpus, Gold, Breeze, Stench = \"A\", \"P\", \"W\", \"G\", \"B\", \"S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f52d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, pitprob, addwumpus=True):\n",
    "        self.pit_prob = pitprob\n",
    "        self.allowclimbwithoutgold = True\n",
    "        self.addwumpus = addwumpus\n",
    "        self.EnvSize = 4\n",
    "        self.getIndexes()\n",
    "        self.getEnv()\n",
    "        self.startloc = self.setAgent(getloc=True)\n",
    "        self.pits = []\n",
    "        self.get_pit_loc()\n",
    "        \n",
    "        \n",
    "    def getMatrix(self, item):\n",
    "        matrix = []\n",
    "        try:\n",
    "            copy = getattr(item, 'copy')\n",
    "        except AttributeError:\n",
    "            copy = None\n",
    "        for i in range(self.EnvSize):\n",
    "            matrix.append([])\n",
    "            for j in range(self.EnvSize):\n",
    "                if copy:\n",
    "                    matrix[i].append(copy())\n",
    "                else:\n",
    "                    matrix[i].append(item)\n",
    "        return matrix\n",
    "\n",
    "\n",
    "    def getIndexes(self):\n",
    "        Indexes = []\n",
    "        for x in range(self.EnvSize):\n",
    "            for y in range(self.EnvSize):\n",
    "                Indexes.append((x, y))\n",
    "        return Indexes\n",
    "\n",
    "    def setElement(self, index, value):\n",
    "        x, y = index\n",
    "        env[x][y] = value\n",
    "        # Removes location from Indexes after it is used.\n",
    "        Indexes.remove(index)\n",
    "\n",
    "    \n",
    "    def randomize_pits(self):\n",
    "        for index in set(Indexes):\n",
    "            setPit = np.random.binomial(1, self.pit_prob, 1)\n",
    "            if setPit==1:\n",
    "                self.setElement(index, Pit)\n",
    "    \n",
    "    def get_pit_loc(self):\n",
    "        pit_loc = np.where(self.environment == \"P\")\n",
    "        [self.pits.append((pit_loc[0][i], pit_loc[1][i])) for i in range(len(pit_loc[0]))]\n",
    "        \n",
    "\n",
    "    def setWumpus(self):\n",
    "        index = random.choice(Indexes)\n",
    "        self.setElement(index, Wumpus)\n",
    "        self.wumpusloc = index\n",
    "            \n",
    "    def setGold(self):\n",
    "        index = random.choice(Indexes)\n",
    "        self.setElement(index, Gold)\n",
    "        self.goldloc = index\n",
    "\n",
    "    def setAgent(self, getloc=False):\n",
    "        index = (3, 0)\n",
    "        if getloc: return index\n",
    "        else:\n",
    "            self.setElement(index, Agent)\n",
    "            self.startloc = index\n",
    "        \n",
    "\n",
    "    def refreshGlobals(self):\n",
    "        global Indexes\n",
    "        global env\n",
    "        Indexes = self.getIndexes()\n",
    "        env = self.getMatrix(0)\n",
    "        return Indexes, env\n",
    "\n",
    "\n",
    "    def getEnv(self):\n",
    "        \"\"\" Returns a new Wumpus World environment \"\"\"\n",
    "        self.refreshGlobals()\n",
    "        self.setAgent()\n",
    "        self.setGold()\n",
    "        if self.addwumpus: self.setWumpus()\n",
    "        else: \n",
    "            self.wumpusloc = None\n",
    "            print(\"üëæ Wumpus not spawned üëæ\")\n",
    "        self.randomize_pits()\n",
    "        self.environment = np.array(env)\n",
    "    \n",
    "    def printEnv(self, target, agentsteps, spath=None, final_state=False, returnpath=False):\n",
    "        state = pd.DataFrame(index=[\"4\",\"3\",\"2\",\"1\"], columns=[\"1\",\"2\",\"3\",\"4\"])\n",
    "        if final_state:\n",
    "            for step in agentsteps:\n",
    "                state.iloc[step] = \"üë£\"\n",
    "        else: state.iloc[agentsteps[-1]] = \"üë£\"\n",
    "        for pit in self.pits:\n",
    "            state.iloc[pit] = \"üï≥Ô∏è\"\n",
    "        if self.goldloc: state.iloc[self.goldloc] = \"üí∞\"\n",
    "        if self.wumpusloc: state.iloc[self.wumpusloc] = \"üëæ\"\n",
    "        if returnpath:\n",
    "            try:\n",
    "                for step in spath:\n",
    "                    state.iloc[step] = \"ü¶∂\"\n",
    "            except: pass\n",
    "        state = state.fillna(\".\")        \n",
    "        print(\"\\nAgent bee line: üë£ |  Shortest route to {}: ü¶∂\\nGold: üí∞ | Wumpus: üëæ | Pits: üï≥Ô∏è | Unattended: .\\n\".format(target))\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1104e662",
   "metadata": {},
   "source": [
    "## Percepts\n",
    "\n",
    "Naive agent has no use for these, unless agent is on gold, wumpus, pit, or exit, which are implemented in the main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f664dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "percept_mapping = {Pit: \"B\", Wumpus: \"S\"}\n",
    "items= {1: \"Agent\", 2: \"Pit\", 3: \"Wumpus\", 4: \"Gold\", 5:\"Breeze\", 6:\"Stench\"}\n",
    "\n",
    "class Percepts(Environment):\n",
    "    def __init__(self, pitprob, addwumpus):\n",
    "        super().__init__(pitprob, addwumpus)       \n",
    "        self.wumpuscry = False\n",
    "        \n",
    "        self.percepts = self.getMatrix(set()) # empty sets containing all state information of each room\n",
    "        \n",
    "        \n",
    "        Indexes = self.getIndexes()\n",
    "        for x, y in Indexes:\n",
    "            if self.environment[x, y] and self.environment[x, y] != \"A\":\n",
    "                self.addPercept((x, y), self.environment[x, y])\n",
    "\n",
    "            if (x + 1, y) in Indexes:\n",
    "                num = percept_mapping.get(self.environment[x + 1, y], None)\n",
    "                if num:\n",
    "                    self.addPercept((x, y), num)\n",
    "\n",
    "            if (x - 1, y) in Indexes:\n",
    "                num = percept_mapping.get(self.environment[x - 1, y], None)\n",
    "                if num:\n",
    "                    self.addPercept((x, y), num)\n",
    "\n",
    "            if (x, y + 1) in Indexes:\n",
    "                num = percept_mapping.get(self.environment[x, y + 1], None)\n",
    "                if num:\n",
    "                    self.addPercept((x, y), num)\n",
    "\n",
    "            if (x, y - 1) in Indexes:\n",
    "                num = percept_mapping.get(self.environment[x, y - 1], None)\n",
    "                if num:\n",
    "                    self.addPercept((x, y), num)\n",
    "                \n",
    "        self.percept_hist = [list(self.getPercept(self.startloc[0], self.startloc[1])),]\n",
    "\n",
    "    def addPercept(self, index, num):\n",
    "        x, y = index\n",
    "        self.percepts[x][y].add(num)\n",
    "\n",
    "    def getPercepts(self):\n",
    "        return self.percepts\n",
    "        \n",
    "    def getPercept(self, x, y):\n",
    "        return (self.percepts[x][y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e1f414",
   "metadata": {},
   "source": [
    "## Knowledge base\n",
    "\n",
    "This knowledge base currently contains information about the environment that the agent doesn't have, however, the agent only uses this information when it is perceived. Future version will put information in it's proper place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac24f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KB(Percepts):\n",
    "    def __init__(self, pitprob, addwumpus):\n",
    "        super().__init__(pitprob, addwumpus)\n",
    "\n",
    "        self.loc_path = [(self.startloc),]\n",
    "        self.curr_dir = [1,] # 0, 1, 2, 3 - up, right, down, left\n",
    "        self.action = [\"Forward\",\"Tright\",\"Tleft\",\"Shoot\", \"Grab\", \"Climb\"]\n",
    "        self.haveGold = False\n",
    "        self.dead = False\n",
    "        self.haveArrow = True\n",
    "        self.arrow_path = []\n",
    "        self.score = 0\n",
    "        self.moves = 0\n",
    "        \n",
    "    def get_arrow_path(self):\n",
    "        if self.haveArrow:\n",
    "            if self.curr_dir[-1] == 0: # Up\n",
    "                for i in range(self.loc_path[-1][0]):\n",
    "                    self.arrow_path.append((self.loc_path[-1][0] - i - 1, self.loc_path[-1][1]))\n",
    "            if self.curr_dir[-1] == 1: # Right\n",
    "                for i in range(len(env) - (self.loc_path[-1][1]) - 1):\n",
    "                    self.arrow_path.append((self.loc_path[-1][0], self.loc_path[-1][1] + i + 1))\n",
    "            if self.curr_dir[-1] == 2: # Down\n",
    "                for i in range(len(env) - self.loc_path[-1][0] - 1):\n",
    "                    self.arrow_path.append((i, self.loc_path[-1][1]))\n",
    "            if self.curr_dir[-1] == 3: # Left\n",
    "                for i in range(self.loc_path[-1][1]):\n",
    "                    self.arrow_path.append((self.loc_path[-1][0], i))\n",
    "    \n",
    "    def get_shortest_route(self, source, target, intermediate):\n",
    "        '''\n",
    "        Note: this includes turns.\n",
    "        '''\n",
    "        G = nx.Graph()\n",
    "        # Adding nodes\n",
    "        if intermediate:\n",
    "            nodes = []\n",
    "            [nodes.append(i) for i in self.loc_path]\n",
    "            nodes.append(target)\n",
    "            \n",
    "        else:\n",
    "            nodes = list(set(self.loc_path))\n",
    "        \n",
    "        for a, (i, j) in enumerate(nodes):\n",
    "            G.add_node(a, coordinate=(i,j))\n",
    "\n",
    "        # mapping nodes to coordinates\n",
    "        dictionary = {}\n",
    "        for e in range(len(G.nodes)):\n",
    "            x = G.nodes[e]['coordinate']\n",
    "            dictionary[x] = e\n",
    "\n",
    "        # adding edges\n",
    "        edges = []\n",
    "\n",
    "        # Connecting nodes for edges\n",
    "        for i in range(10**(self.EnvSize-1)):\n",
    "            a = random.choice(nodes)\n",
    "            b = random.choice(nodes)\n",
    "            if a[0] == b[0] and (np.absolute(a[1] - b[1]) == 1):        \n",
    "                edges.append((a, b))\n",
    "            elif a[1] == b[1] and (np.absolute(a[0] - b[0])== 1):\n",
    "                edges.append((a, b))\n",
    "        edges = set(edges)\n",
    "\n",
    "        # generating edges\n",
    "        edge_list = []\n",
    "        for i, j in edges:\n",
    "            x, y = dictionary.get(i), dictionary.get(j)\n",
    "            edge_list.append((x,y))\n",
    "\n",
    "        for i in edge_list:\n",
    "            G.add_edge(*i)\n",
    "\n",
    "        # remapping nodes to coordinates\n",
    "        all_paths = nx.all_simple_paths(G, source=dictionary.get(source), target=dictionary.get(target))\n",
    "        paths = []\n",
    "        for i in all_paths:\n",
    "            paths.append(i)\n",
    "\n",
    "        dictionaries = []\n",
    "        [dictionaries.append(dict()) for i in range(len(paths))]\n",
    "        \n",
    "        for i in range(len(dictionaries)):\n",
    "            for j in paths[i]:\n",
    "                x = G.nodes[j]['coordinate']\n",
    "                dictionaries[i][j] = x\n",
    "\n",
    "        paths_back = []\n",
    "        [paths_back.append(list()) for i in range(len(paths))]\n",
    "\n",
    "        for i in range(len(dictionaries)):\n",
    "            for j in paths[i]:    \n",
    "                x, y = dictionaries[i].get(j)\n",
    "                paths_back[i].append((x,y))\n",
    "\n",
    "        lengths = []\n",
    "        for i in range(len(dictionaries)):\n",
    "            lengths.append(len(paths_back[i]))\n",
    "            for j in range(len(paths_back[i])):\n",
    "                try:\n",
    "                    if (paths_back[i][j+1][0] == paths_back[i][j][0]) and (paths_back[i][j+1][1] != paths_back[i][j][1]):\n",
    "                        if (paths_back[i][j+2][0] != paths_back[i][j+1][0]):\n",
    "                            lengths[i] += 1\n",
    "                    elif (paths_back[i][j+1][1] == paths_back[i][j][1]) and (paths_back[i][j+1][0] != paths_back[i][j][0]):\n",
    "                        if (paths_back[i][j+2][1] != paths_back[i][j+1][1]):\n",
    "                            lengths[i] += 1\n",
    "                    else: pass\n",
    "                except: pass\n",
    "\n",
    "        # Original paths without turns        \n",
    "        lengths2 = []\n",
    "        for i in range(len(dictionaries)):\n",
    "            lengths2.append(len(paths_back[i]))\n",
    "#         shortest path back considering turns\n",
    "        try: shortest_path_back = paths_back[lengths.index(min(lengths))]\n",
    "        except: shortest_path_back = [self.loc_path[-1]]\n",
    "        # number of turns\n",
    "        try: no_turns = lengths[lengths.index(min(lengths))] - lengths2[lengths.index(min(lengths))]\n",
    "        except: no_turns = 0\n",
    "        # execute path\n",
    "        try: [self.loc_path.append(shortest_path_back[i+1]) for i in range(len(shortest_path_back)-1)]\n",
    "        except: pass\n",
    "        return shortest_path_back, no_turns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dda5511",
   "metadata": {},
   "source": [
    "## Actuators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34460f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actuators(KB):\n",
    "    def __init__(self, pitprob, addwumpus, verbose):\n",
    "        super().__init__(pitprob, addwumpus)\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def forward(self, direction):\n",
    "        if direction == 0: # facing up\n",
    "            self.loc_path.append((self.loc_path[-1][0]-1, self.loc_path[-1][1]))\n",
    "        elif direction == 1: # facing right\n",
    "            self.loc_path.append((self.loc_path[-1][0], self.loc_path[-1][1]+1))\n",
    "        elif direction == 2: # facing down\n",
    "            self.loc_path.append((self.loc_path[-1][0] + 1, self.loc_path[-1][1]))\n",
    "        else: # facing left\n",
    "            self.loc_path.append((self.loc_path[-1][0], self.loc_path[-1][1]-1))\n",
    "        self.score -= 1\n",
    "        if self.verbose: \n",
    "            print(\"Current score: {}\".format(self.score))\n",
    "        try:\n",
    "            self.percept_hist.append(list(self.getPercept(self.loc_path[-1][0], self.loc_path[-1][1])))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def bump(self):\n",
    "        if len(self.loc_path) > 1:\n",
    "            self.loc_path.pop(-1)\n",
    "        if self.verbose: \n",
    "            print(\"Agent attempts to move, bupms into a wall.\")\n",
    "            print(\"Current score: {}\".format(self.score))\n",
    "    \n",
    "    def turnright(self, direction):\n",
    "        if direction < 3: self.curr_dir.append(self.curr_dir[-1]+1)\n",
    "        else: self.curr_dir.append(0)\n",
    "        self.score -= 1\n",
    "        if self.verbose: \n",
    "            print(\"Agent turns right.\")\n",
    "            print(\"Current score: {}\".format(self.score))\n",
    "        \n",
    "    def turnleft(self, direction):\n",
    "        if direction > 0: self.curr_dir.append(self.curr_dir[-1]-1)                 \n",
    "        else: self.curr_dir.append(3)\n",
    "        self.score -= 1\n",
    "        if self.verbose: \n",
    "            print(\"Agent turns left.\")\n",
    "            print(\"Current score: {}\".format(self.score))\n",
    "        \n",
    "    def shoot(self, probagent):\n",
    "        arrow_path = self.arrow_path\n",
    "        if self.verbose: print(\"üèπüèπ Agent fires arrow üèπüèπ\")\n",
    "        if not probagent:\n",
    "            if self.wumpusloc and (self.wumpusloc in arrow_path):\n",
    "                self.wumpuscry = True\n",
    "                self.wumpusloc = None\n",
    "                if self.verbose: print(\"Wumpus killed!\")\n",
    "            else: \n",
    "                if self.verbose:\n",
    "                    print(\"Arrow misses its mark\")\n",
    "        else:\n",
    "            self.wumpuscry = True\n",
    "            self.wumpusloc = None\n",
    "            if self.verbose: print(\"Wumpus killed!\")\n",
    "        self.haveArrow = False\n",
    "        self.score -= 10\n",
    "    \n",
    "    \n",
    "    def grab(self, probagent):\n",
    "        if self.verbose: print(\"Agent attempts to grab something.\")\n",
    "        if not probagent:\n",
    "            if (self.goldloc == self.loc_path[-1]) and not self.haveGold:\n",
    "                self.haveGold = True\n",
    "                if self.verbose: print(\"üí∞üí∞Agent picks up the goldüí∞üí∞\")\n",
    "                self.goldloc = None\n",
    "            else: \n",
    "                if self.verbose: \n",
    "                    print(\"Agent grabs nothing.\")\n",
    "                    print(\"Current score: {}\".format(self.score))\n",
    "        else: \n",
    "            self.haveGold = True\n",
    "            if self.verbose: print(\"üí∞üí∞Agent picks up the goldüí∞üí∞\")\n",
    "            self.goldloc = None\n",
    "        \n",
    "        self.score -= 1\n",
    "        \n",
    "        \n",
    "    def climb(self, allowclimbwithoutgold=True):\n",
    "        if not allowclimbwithoutgold:\n",
    "            if self.havegold:\n",
    "                print(\"Agent climbs out with the gold\")\n",
    "                self.score += (1000 - 1)\n",
    "            else:\n",
    "                if self.verbose:\n",
    "                    print(\"Agent attempts to climb out but does not have the gold.\")\n",
    "\n",
    "        else:\n",
    "            if self.haveGold:\n",
    "                self.score += 1000\n",
    "                if self.verbose: print(\"üéâüéâAgent climbs out of the cave with the gold.üéâüéâ\")\n",
    "            else: \n",
    "                if self.verbose: print(\"Agent climbs out without the gold.\")\n",
    "        self.score -= 1\n",
    "        if self.verbose: print(\"Final score: \", self.score)\n",
    "       \n",
    "    \n",
    "    def make_shortest_turn(self, pathback): # note the use of a numpy array means indexes for rows are inversed\n",
    "\n",
    "        current = pathback[0]\n",
    "        try: nextone = pathback[1]\n",
    "        except: nextone = current\n",
    "\n",
    "        if nextone != current:\n",
    "            if current[0] != nextone[0] and current[1] == nextone[1]:\n",
    "                if current[0] > nextone[0]: # if shortest way back starts above agent\n",
    "\n",
    "                    if self.curr_dir[-1] == 1: self.turnleft(direction=1)\n",
    "                    elif self.curr_dir[-1] == 3: self.turnright(direction=3)\n",
    "                    elif self.curr_dir[-1] == 2:# if agent facing down, turn right twice  (or left, it doesn't matter)\n",
    "                        self.turnright(direction=2), self.turnright(direction=3)\n",
    "                    else: pass\n",
    "\n",
    "                elif current[0] < nextone[0]: # if shortest way back starts below agent\n",
    "\n",
    "                    if self.curr_dir[-1] == 1: self.turnright(direction=1)\n",
    "                    elif self.curr_dir[-1] == 3: self.turnleft(direction=3)\n",
    "                    elif self.curr_dir[-1] == 0: # if agent facing up, turn right twice (or left, it doesn't matter)\n",
    "                        self.turnright(direction=0), self.turnright(direction=1)\n",
    "                    else: pass\n",
    "                else: pass\n",
    "\n",
    "            elif current[0] == nextone[0] and current[1] != nextone[1]:\n",
    "\n",
    "                if current[1] > nextone[1]: # if shortest way back starts left of agent\n",
    "\n",
    "                    if self.curr_dir[-1] == 0: self.turnleft(direction=0)\n",
    "                    elif self.curr_dir[-1] == 2: self.turnright(direction=2)\n",
    "                    elif self.curr_dir[-1] == 1: # if agent facing right, turn right twice (or left, it doesn't matter)\n",
    "                        self.turnright(direction=1), self.turnright(direction=2) \n",
    "                    else: pass\n",
    "\n",
    "                elif current[1] < nextone[1]: # if shortest way back starts right of agent\n",
    "\n",
    "                    if self.curr_dir[-1] == 0: self.turnright(direction=0)\n",
    "                    elif self.curr_dir[-1] == 2: self.turnleft(direction=2)\n",
    "                    elif self.curr_dir[-1] == 3: # if agent facing left, turn right twice (or left, it doesn't matter)\n",
    "                        self.turnright(direction=3), self.turnright(direction=0)\n",
    "                    else: pass\n",
    "                else: pass\n",
    "            else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7975590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pit_wumpus_networks import *\n",
    "from wumpusworld import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88bad6a3-c4dd-412f-a1fa-f21c578abc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbAgent(Actuators):\n",
    "    def __init__(self, pitprob, addwumpus, verbose):\n",
    "        super().__init__(pitprob, addwumpus, verbose)\n",
    "        self.pitprob = pitprob\n",
    "        self.beliefs = self.populate_beliefs()\n",
    "        self.confirmedpits = []\n",
    "        self.confirmedwumpus = None\n",
    "        self.get_beliefs()\n",
    "        self.getPercepts()\n",
    "    \n",
    "    def populate_beliefs(self):\n",
    "        beliefs = np.array(self.getMatrix(dict()))\n",
    "        items = [\"Ok\", \"Known\", \"Frontier\", \"Stench\", \"Wumpus\", \"Breeze\", \"Pit\"]\n",
    "        for item in items:\n",
    "            for i in range(self.EnvSize):\n",
    "                for j in range(self.EnvSize):\n",
    "                    (beliefs[i, j])[\"{}\".format(item)] = 0\n",
    "        return beliefs\n",
    "    \n",
    "    def get_beliefs(self):\n",
    "\n",
    "        # updating confirmed pits/no pits, ok/not ok locations, non-frontier locations,          \n",
    "        Indexes = self.getIndexes()\n",
    "        if len(self.confirmedpits) > 0: #and any(loc in adjacents for loc in self.confirmedpits):\n",
    "            for loc in self.confirmedpits:\n",
    "                (self.beliefs[loc])[\"Pit\"] = 1            \n",
    "        for loc in self.loc_path:\n",
    "            self.beliefs[loc][\"Ok\"] = 1\n",
    "            self.beliefs[loc][\"Frontier\"] = 0\n",
    "            self.beliefs[loc][\"Pit\"] = 0\n",
    "        \n",
    "        # Updating frontier, confirmed stench and breeze\n",
    "        for loc in self.loc_path:\n",
    "            i, j = loc[0], loc[1]\n",
    "            \n",
    "            percept = self.getPercept(i, j)\n",
    "            if \"S\" in percept: self.beliefs[(i,j)][\"Stench\"] = 1\n",
    "            if \"B\" in percept: self.beliefs[(i,j)][\"Breeze\"] = 1\n",
    "                    \n",
    "            adjacents = [(i+1,j),(i-1,j),(i,j+1),(i,j-1)]        \n",
    "            for a in adjacents:\n",
    "                if (a not in self.loc_path) and (a in Indexes) and (self.beliefs[a][\"Pit\"] != 1):\n",
    "                    (self.beliefs[a])[\"Frontier\"] = 1\n",
    "            \n",
    "                \n",
    "                    \n",
    "    def get_wumpus_proba(self, confirmedpits, stenchsensed, wumpustarget, wumpusalive):\n",
    "        model = bake_wumpus_network(confirmedpits=confirmedpits, wumpusalive=wumpusalive, wumpusspawned=self.addwumpus)\n",
    "        query, wumpusprobs = dict(), []\n",
    "        for i in range(len(stenchsensed)):\n",
    "            query[\"Stench{}{}\".format(stenchsensed[i][0][0], stenchsensed[i][0][1])] = \"{}\".format(stenchsensed[i][1])\n",
    "        dist = model.predict_proba([query])[0][0].parameters[0]\n",
    "\n",
    "        for loc in (wumpustarget):\n",
    "            prob = [(loc[0], loc[1]), dist[\"{},{}\".format(loc[0], loc[1])]]\n",
    "            wumpusprobs.append(prob)\n",
    "        return wumpusprobs\n",
    "    \n",
    "    def get_pit_proba(self, wumpusloc, breezelocs, pitlocs, targetpit):\n",
    "        if wumpusloc: model = bake_pit_network(wumpusloc=wumpusloc[0], pitprob=self.pitprob)\n",
    "        else: model = bake_pit_network(wumpusloc=None, pitprob=self.pitprob)\n",
    "#         pits = self.getIndexes()\n",
    "        pits = [(0,0),(0,1),(0,2),(0,3), (1,0),(1,1),(1,2),(1,3), \n",
    "                (2,0),(2,1),(2,2),(2,3), (3,0),(3,1),(3,2),(3,3)]\n",
    "        \n",
    "        target, pitprobs, query = [], [], {}\n",
    "        \n",
    "        target.append([pits.index(i) for i in targetpit])\n",
    "        for i in range(30):\n",
    "            try:\n",
    "                query[\"Breeze{}{}\".format((breezelocs[i][0][0]), \n",
    "                                               (breezelocs[i][0][1]))] = \"{}\".format(breezelocs[i][1])\n",
    "                query[\"Pit{}{}\".format((pitlocs[i][0][0]), \n",
    "                                            (pitlocs[i][0][1]))] = \"{}\".format(pitlocs[i][1])\n",
    "            except: pass\n",
    "        for i, j in enumerate(target[0]):\n",
    "            pitprobs.append([((targetpit[i][0]), (targetpit[i][1])), model.predict_proba([query])[0][j].parameters[0].get(\"1\")])\n",
    "        return pitprobs\n",
    "\n",
    "    def confirmed_pit_wumpus(self,pitprob, wumpusprob):\n",
    "        # update beliefs if wumpus location is confirmed\n",
    "        \n",
    "        if (not self.wumpuscry) and (not self.confirmedwumpus):\n",
    "            for loc in wumpusprob:\n",
    "                if loc[1]==1: \n",
    "                    self.beliefs[loc[0]][\"Wumpus\"] = 1\n",
    "                    self.confirmedwumpus=1\n",
    "                else: pass\n",
    "        # update beliefs if pit location is confirmed\n",
    "        for loc in pitprob:\n",
    "            if loc[1]==1: \n",
    "                self.beliefs[loc[0]][\"Pit\"] = 1\n",
    "                self.confirmedpits.append(loc[0])\n",
    "\n",
    "    def shoot_wumpus(self, wumpus):\n",
    "        candidates, distances = [], []\n",
    "        # get possible points form which wumpus may be shot at\n",
    "        for loc in set(self.loc_path):\n",
    "            try:\n",
    "                if loc[0] == self.confirmedwumpus[0][0] or loc[1] == self.confirmedwumpus[0][1]:\n",
    "                    candidates.append(loc)\n",
    "            except:pass\n",
    "        # get closes of above points to current agent location\n",
    "        for loc in candidates:\n",
    "            euclidist = ((self.loc_path[-1][0] - loc[0])**2 + (self.loc_path[-1][1] - loc[1])**2)**0.5\n",
    "            distances.append(euclidist)\n",
    "        elected = candidates[np.argmin(distances)]\n",
    "        if self.verbose:\n",
    "            print(\"Agent confirms existence of wumpus. Agent is currently at {} and moved to {} to shoot the wumpus.\"\n",
    "                  .format(self.loc_path[-1], elected))\n",
    "        path = self.get_shortest_route(source=self.loc_path[-1], target=elected, intermediate=True) # get shortest path\n",
    "        self.make_shortest_turn(pathback=path[0])                                # turn to shortest path\n",
    "        self.make_shortest_turn(pathback=[self.loc_path[-1], wumpus[0]]) # turn to face wumpus\n",
    "        if self.verbose:\n",
    "            display(self.printEnv(agentsteps=self.loc_path, spath=path[0], final_state=True, returnpath=True, target=elected))\n",
    "            print(\"Agent facing:\", self.curr_dir[-1], \"\\n [0: Up | 1: Right | 2: Down | 3: Left]\")\n",
    "        self.shoot(probagent=True)\n",
    "        \n",
    "        # updating sense map and beliefs to remove wumpus and stench and mark wumpus loc as Ok\n",
    "        Indexes = self.getIndexes()\n",
    "        for loc in Indexes:\n",
    "            self.beliefs[loc][\"Wumpus\"] = 0\n",
    "            self.beliefs[loc][\"Stench\"] = 0\n",
    "            self.percepts[loc[0]][loc[1]].discard(\"W\")\n",
    "            self.percepts[loc[0]][loc[1]].discard(\"S\")\n",
    "        self.beliefs[self.confirmedwumpus[0]][\"Ok\"] = 1\n",
    "                \n",
    "        \n",
    "    def decide_on_action(self, risk):\n",
    "        if self.verbose: \n",
    "            display(self.printEnv(agentsteps=self.loc_path, spath=None, final_state=False, returnpath=False, target=None))\n",
    "            display(\"Percepts: \\n\", pd.DataFrame(self.percepts))\n",
    "\n",
    "        targets, pits, breezes, stenches, candidates, elected = [], [], [], [], [], []\n",
    "        self.get_beliefs()\n",
    "        \n",
    "        Indexes = self.getIndexes()\n",
    "        for loc in Indexes:\n",
    "            if self.beliefs[loc][\"Frontier\"] == 1 and loc not in self.confirmedpits: targets.append(loc)\n",
    "            if self.beliefs[loc][\"Pit\"] == 1: pits.append([loc, 1])\n",
    "        for loc in set(self.loc_path):\n",
    "            if self.beliefs[loc][\"Breeze\"] == 1: breezes.append([loc, 1])\n",
    "            else: breezes.append([loc, 0])\n",
    "            if self.beliefs[loc][\"Stench\"] == 1: stenches.append([loc, 1])\n",
    "            else: stenches.append([loc, 0])\n",
    "            if self.beliefs[loc][\"Pit\"] == 0: pits.append([loc, 0])\n",
    "        if self.verbose: \n",
    "            print(\"Targets:\", targets)\n",
    "            print(\"Breeze\", breezes)\n",
    "            print(\"Stenches\", stenches)\n",
    "            print(\"Pits\", pits)\n",
    "        \n",
    "        pitproba = self.get_pit_proba(wumpusloc=self.confirmedwumpus, breezelocs = breezes, pitlocs = pits, targetpit = targets)\n",
    "        wumpusproba = self.get_wumpus_proba(confirmedpits=self.confirmedpits, stenchsensed = stenches, wumpustarget = targets, wumpusalive=(False == self.wumpuscry))\n",
    "        \n",
    "        if self.verbose: display(\"Wumpus probs:\",wumpusproba)\n",
    "\n",
    "        if not self.wumpuscry: \n",
    "            for loc in wumpusproba:\n",
    "                if loc[1] == 1: \n",
    "                    self.confirmedwumpus = [loc[0]]\n",
    "                    self.shoot_wumpus(self.confirmedwumpus)\n",
    "                    self.wumpuscry=True\n",
    "                    if self.verbose: display(np.array(self.percepts))\n",
    "            # Update probability if wumpus killed:\n",
    "            wumpusproba = self.get_wumpus_proba(confirmedpits=self.confirmedpits, stenchsensed = stenches, wumpustarget = targets, wumpusalive=(False == self.wumpuscry))\n",
    "            if self.verbose: display(\"New wumpus probs:\",wumpusproba)\n",
    "        \n",
    "        self.confirmed_pit_wumpus(pitprob=pitproba, wumpusprob=wumpusproba)\n",
    "        if self.verbose:\n",
    "            display(\"Pit probs:\", pitproba)\n",
    "            display(self.beliefs)\n",
    "            \n",
    "            print(\"Targets:\", targets)\n",
    "            print(\"Breeze\", breezes)\n",
    "            print(\"Stenches\", stenches)\n",
    "            print(\"Pits\", pits)\n",
    "\n",
    "        # if gold is found, head for exit and escape\n",
    "        \n",
    "        \n",
    "        for i, j in zip(pitproba, wumpusproba):\n",
    "            try:\n",
    "                x = np.argmax([i[1], j[1]])\n",
    "                if x == 1: candidates.append(j)\n",
    "                elif x == 0: candidates.append(i)\n",
    "            except: candidates.append(pitproba[i], wumpusproba[j]) \n",
    "        if self.verbose: \n",
    "            print(\"Candidates: \", candidates)\n",
    "        \n",
    "        [elected.append(candidates[i][1]) for i in range(len(candidates))]\n",
    "        if self.verbose: print(\"Probabilities of candiadte pits: \",elected)\n",
    "        try: elected = candidates[np.argmin(elected)]\n",
    "        except:\n",
    "            return \"no next move\"\n",
    "        if self.verbose: print(\"Chosen location: \", elected)\n",
    "\n",
    "        \n",
    "        # move to another location if nothing in this location and if it is safe to move\n",
    "        # else, quit        \n",
    "        if elected[1] < risk: # move\n",
    "            path = self.get_shortest_route(source=self.loc_path[-1], target=elected[0], intermediate=True)\n",
    "            self.make_shortest_turn(pathback=path[0])\n",
    "            self.score -= (len(path[0]) + path[1] - 1) # excludes current room\n",
    "            if self.verbose:\n",
    "                print(\"Agent moves to: \", self.loc_path[-1], \"Score: \", self.score)\n",
    "                print(\"Target location: \", elected[0],\"Agent path: \", self.loc_path)\n",
    "            \n",
    "            if elected[0] in self.pits:\n",
    "                if self.verbose: display(self.printEnv(agentsteps=self.loc_path, spath=path[0], final_state=True, returnpath=True, target=self.loc_path[-1]))\n",
    "                self.score -= 1000\n",
    "                print(\"üï≥Ô∏è Agent falls into a pit and dies. üï≥Ô∏è\")\n",
    "                return \"no next move\"\n",
    "\n",
    "            elif (not self.wumpuscry) and elected[0] == self.wumpusloc:\n",
    "                if self.verbose: display(self.printEnv(agentsteps=self.loc_path, spath=path[0], final_state=True, returnpath=True, target=self.wumpusloc))\n",
    "                self.score -= 1000\n",
    "                print(\"üëæ Agent falls victim to the wumpus. üëæ\")\n",
    "                return \"no next move\"\n",
    "            elif elected[0] == self.goldloc:\n",
    "                self.loc_path.append(self.goldloc)\n",
    "                self.grab(probagent=1)\n",
    "                path = self.get_shortest_route(source=self.loc_path[-1], target=self.loc_path[0], intermediate=False)\n",
    "                self.make_shortest_turn(pathback=path[0])\n",
    "                self.score -= (len(path[0]) + path[1] - 1) # excludes current room\n",
    "                self.climb()\n",
    "                display(self.printEnv(agentsteps=self.loc_path, spath=path[0], final_state=True, returnpath=True, target=self.loc_path[0]))\n",
    "                return \"no next move\"\n",
    "            else:             \n",
    "                display(self.printEnv(agentsteps=self.loc_path, spath=path[0], final_state=True, returnpath=True, target=elected[0]))\n",
    "                return \"move\"\n",
    "\n",
    "        else: # quit\n",
    "            if self.verbose: display(\"Too risky! Quitting...\")\n",
    "            path = self.get_shortest_route(source=self.loc_path[-1], target=self.loc_path[0], intermediate=False)\n",
    "            self.make_shortest_turn(pathback=path[0])\n",
    "            self.score -= (len(path[0]) + path[1] - 1) # excludes current room\n",
    "            display(self.printEnv(agentsteps=self.loc_path, spath=path[0], final_state=True, returnpath=True, target=self.loc_path[0]))\n",
    "            self.climb()\n",
    "\n",
    "            return \"no next move\"\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d4bbfa",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f61c1a",
   "metadata": {},
   "source": [
    "Initialize/refresh environment:\n",
    "\n",
    "**1. Pitprob** - set pit probability between 0 (for no pits) and 1 (all other room have pits) for testing functionality\n",
    "\n",
    "**2. Addwumpus** - add wumpus (True/False) for testing functionality\n",
    "\n",
    "**3. Verbose** - \n",
    "    True: shows every detail of environment and probabilistic thinking\n",
    "    False: Shows final score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f663a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(verbose=False, addwumpus=False, pitprob=0.2, risk=0.33): # risk  34.3, 34.4 is optimal\n",
    "    PA = ProbAgent(addwumpus=addwumpus, verbose=verbose, pitprob=pitprob)\n",
    "    next_move = \"move\"\n",
    "    while next_move == \"move\":\n",
    "        move = PA.decide_on_action(risk=risk)\n",
    "        next_move = move\n",
    "    return PA.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "368911d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-65448be4c9b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msimulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maddwumpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpitprob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrisk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-f4089de36c82>\u001b[0m in \u001b[0;36msimulate\u001b[1;34m(verbose, addwumpus, pitprob, risk)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mnext_move\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"move\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecide_on_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrisk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrisk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magentsteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturnpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0melected\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mnext_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mPA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "simulate(verbose=0, addwumpus=1, pitprob=0.2, risk=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7a1ad1",
   "metadata": {},
   "source": [
    "#### Optimizing probability of surivival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2630ad1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal risk at which agent should quit is when probability of death is greater than  0.33\n"
     ]
    }
   ],
   "source": [
    "risks = np.arange(30, 38, 0.5)\n",
    "means = []\n",
    "for j in risks:\n",
    "#     print(j)\n",
    "    scores = []\n",
    "    for i in range(500):\n",
    "        score = simulate(verbose=False, addwumpus=True, pitprob=0.2, risk=j)\n",
    "        scores.append(score)\n",
    "    means.append(np.mean(scores))\n",
    "print(\"Optimal risk at which agent should quit is when probability of death is greater than \", risks[np.argmax(means)]/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7ca2df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Score vs Risk Tradeoff'}>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(data=(means), index=risks/100).plot(title=\"Score vs Risk Tradeoff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b1545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
